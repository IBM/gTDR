{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import yaml\n",
    "import types\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toolkit\n",
    "from gTDR.datasets import GANF_Dataset\n",
    "from gTDR.models import GANF\n",
    "from gTDR.trainers.GANF_trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fc732a",
   "metadata": {},
   "source": [
    "## Arguments & Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71043c69",
   "metadata": {},
   "source": [
    "Specify the setup in config, including:\n",
    "* `data_dir`: (str) Path to the dataset to be used for training the model.\n",
    "* `name`: (str) Name of the model run. This can be used to identify different runs or configurations.\n",
    "* `seed`: (int) Random seed for reproducibility.\n",
    "* `use_cuda`: (bool) Whether to use CUDA for training. If True and a GPU is available, the model will be trained on the GPU.\n",
    "* `save_results`: (bool) Whether to save the training checkpoints.\n",
    "* `output_dir`: (str) Directory to save the trainer's checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = \"../configs/GANF_METR_LA_parameters.yaml\"\n",
    "with open(config_filename) as f:\n",
    "    configs = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "args = types.SimpleNamespace(**configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a03c4",
   "metadata": {},
   "source": [
    "Use GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42637270",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_cuda = (torch.cuda.is_available() and args.use_cuda)\n",
    "if args.use_cuda:\n",
    "    args.device = 'cuda'\n",
    "else:\n",
    "    args.device = 'cpu'\n",
    "print (\"use CUDA:\", args.use_cuda, \"- device:\", args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f66534",
   "metadata": {},
   "source": [
    "Set seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = args.seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if args.use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1351da",
   "metadata": {},
   "source": [
    "Start `wandb` for monitoring experiment (train loss, validation loss, test loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc870522",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"GANF\", name=\"METR-LA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb27b8",
   "metadata": {},
   "source": [
    "## Data (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98822c4e",
   "metadata": {},
   "source": [
    "In this demo, we use the `METR-LA` dataset.\n",
    "\n",
    "**First, unzip dataset located at [../data/METR-LA/](../data/METR-LA/):**\n",
    "\n",
    "`gunzip -c ../data/METR-LA/metr-la.h5.zip > ../data/METR-LA/metr-la.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122af6f",
   "metadata": {},
   "source": [
    "## Data (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a43bf",
   "metadata": {},
   "source": [
    "Next, create dataloaders.\n",
    "\n",
    "GANF defines a dataset class `GANF_Dataset` inherited from `torch.utils.data.Dataset`. This class takes a DataFrame of sensor readings (`df`) and optional labels (`label`), as well as a window size and stride size for the sliding windows. It preprocesses the data to create sliding windows of sensor readings and keeps track of the labels associated with each window.\n",
    "\n",
    "Here, we define a function `load_traffic()` to load the dataset file `metr-la.h5`, perform feature normalization, conduct data split, and create dataloaders by taking `GANF_Dataset` objects for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59368d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_traffic(root, batch_size):\n",
    "    \"\"\"\n",
    "    Load traffic dataset\n",
    "    return train_loader, val_loader, test_loader\n",
    "    \"\"\"\n",
    "    df = pd.read_hdf(root)\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"index\":\"utc\"})\n",
    "    df[\"utc\"] = pd.to_datetime(df[\"utc\"], unit=\"s\")\n",
    "    df = df.set_index(\"utc\")\n",
    "    n_sensor = len(df.columns)\n",
    "\n",
    "    mean = df.values.flatten().mean()\n",
    "    std = df.values.flatten().std()\n",
    "\n",
    "    df = (df - mean)/std\n",
    "    df = df.sort_index()\n",
    "    # split the dataset\n",
    "    train_df = df.iloc[:int(0.75*len(df))]\n",
    "    val_df = df.iloc[int(0.75*len(df)):int(0.875*len(df))]\n",
    "    test_df = df.iloc[int(0.75*len(df)):]\n",
    "\n",
    "    train_loader = DataLoader(GANF_Dataset(train_df), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(GANF_Dataset(val_df), batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(GANF_Dataset(test_df), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, n_sensor  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8d88e-b4b6-41ac-bb16-6ae8cfd085fd",
   "metadata": {},
   "source": [
    "Create dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98959587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, n_sensor = load_traffic(\"{}/metr-la.h5\".format(args.data_dir), \\\n",
    "                                                                args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6dae94",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec30148",
   "metadata": {},
   "source": [
    "You may specify these model parameters in config:\n",
    "\n",
    "* `input_size`: (int) Size of the input data for the GNN and NF models.\n",
    "\n",
    "* `hidden_size`: (int) Size of the hidden layers in the GNN.\n",
    "\n",
    "* `n_hidden`: (int) Number of hidden layers in the NF model.\n",
    "\n",
    "* `dropout`: (float) Dropout rate for the LSTM layer in the GANF model.\n",
    "\n",
    "* `n_blocks`: (int) Number of flow blocks in the NF model.\n",
    "\n",
    "* `batch_norm`: (bool) Whether to use batch normalization in the NF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GANF(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8582b08d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da07dd",
   "metadata": {},
   "source": [
    "You may specify these training parameters in config:\n",
    "\n",
    "* `batch_size`: (int) Number of samples per batch during training. This is the number of samples that the model will process at one time.\n",
    "\n",
    "* `weight_decay`: (float) Weight decay (L2 penalty) for the optimizer. This can help to prevent overfitting.\n",
    "\n",
    "* `n_epochs`: (int) Number of training epochs. An epoch is one complete pass through the entire training dataset.\n",
    "\n",
    "* `additional_iter`: (int) Number of additional iterations for the second stage training.\n",
    "\n",
    "* `lr`: (float) Learning rate for the optimizer. This controls the size of the updates to the model's parameters during training.\n",
    "\n",
    "* `max_iter`: (int) Maximum number of iterations for the training.\n",
    "\n",
    "* `h_tol`: (float) Tolerance for the stopping criterion.\n",
    "\n",
    "* `rho`: (float) This is a regularization parameter in the Alternating Direction Method of Multipliers (ADMM) algorithm. It balances the trade-off between the loss function and the constraints in the optimization problem. A larger value of `rho` can make the constraints more strictly enforced, while a smaller value can make the solution focus more on minimizing the loss function.\n",
    "\n",
    "* `rho_max`: (float) This is the maximum value that `rho` can take. In ADMM, `rho` is allowed to increase adaptively during the training process to enforce the constraints more strictly. `rho_max` sets an upper limit to prevent `rho` from becoming too large.\n",
    "\n",
    "* `alpha`: (float) This is a parameter that controls the over-relaxation in the ADMM algorithm. It is used to accelerate the convergence of the algorithm. The value of `alpha` is typically between 1 and 2. A value of 1 corresponds to no over-relaxation, while values greater than 1 correspond to increasing degrees of over-relaxation.\n",
    "\n",
    "* `graph_dir`: (str) Directory containing the graph structure for the model. If provided, the model will initialize its graph structure from this file. If not provided, the model will initialize its graph structure randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75822606",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(args, model, n_sensor, train_loader, val_loader, test_loader, has_label=False) \n",
    "trainer.train(use_wandb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b995f0",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c309cdb",
   "metadata": {},
   "source": [
    "Load the best check point and perform testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf07feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_best_checkpoint()\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
